# RLM Project (Local-First)

Purpose:
- Build a local-first recursive language memory system.
- Private layer (raw + full summaries) stays local.
- Public layer (redacted summaries + tags) can be shared externally.

Architecture:
- core/       index + redaction + retrieval logic
- models/     local model adapters (Ollama, llama.cpp)
- storage/    SQLite + embeddings or keyword index
- api/        local API server
- ui/         web UI / Portal integration
- tools/      scripts + CLI

Next:
- Wire Ollama adapter
- Build SQLite schema
- Create indexer + redactor
